{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning en Computer Vision\n",
    "\n",
    "## 📚 Introduction\n",
    "\n",
    "### 🎯 Qu'est-ce que le Fine-Tuning ?\n",
    "\n",
    "Le fine-tuning est une technique d'apprentissage par transfert qui consiste à :\n",
    "\n",
    "1. **Partir d'un modèle pré-entraîné** (comme MobileNetV2 entraîné sur ImageNet)\n",
    "2. **Adapter ce modèle** à notre problème spécifique\n",
    "3. **Réentraîner partiellement** le modèle sur nos données\n",
    "\n",
    "### 💡 Pourquoi utiliser le Fine-Tuning ?\n",
    "\n",
    "✅ **Moins de données nécessaires** : Utilise les connaissances déjà apprises\n",
    "\n",
    "✅ **Entraînement plus rapide** : Pas besoin de partir de zéro\n",
    "\n",
    "✅ **Meilleures performances** : Combine les features génériques et spécifiques\n",
    "\n",
    "✅ **Moins de ressources** : Économise du temps de calcul\n",
    "\n",
    "### 🌺 Notre Projet\n",
    "\n",
    "Dans ce notebook, nous allons :\n",
    "- Classifier 5 types de fleurs différentes\n",
    "- Utiliser le modèle MobileNetV2 pré-entraîné\n",
    "- Appliquer deux phases d'entraînement\n",
    "- Visualiser nos résultats à chaque étape\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Configuration et Imports\n",
    "\n",
    "Commençons par importer toutes les bibliothèques nécessaires et configurer notre environnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 TensorFlow version: 2.19.0\n",
      "💻 GPU disponible: ❌ Non\n"
     ]
    }
   ],
   "source": [
    "# Imports principaux\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration pour un meilleur affichage\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(f\"🚀 TensorFlow version: {tf.__version__}\")\n",
    "print(f\"💻 GPU disponible: {'✅ Oui' if len(tf.config.list_physical_devices('GPU')) > 0 else '❌ Non'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🖥️ Configuration GPU\n",
    "\n",
    "Si vous avez un GPU, nous allons le configurer pour éviter les erreurs de mémoire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration GPU pour éviter les erreurs OOM (Out of Memory)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Limiter la croissance de la mémoire GPU\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"✅ Configuration GPU réussie - Croissance mémoire activée\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"⚠️ Erreur configuration GPU: {e}\")\n",
    "else:\n",
    "    print(\"🔧 Utilisation du CPU - Pas de GPU détecté\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚙️ Paramètres d'Entraînement\n",
    "\n",
    "Définissons les paramètres principaux de notre modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Paramètres du modèle\n",
    "BATCH_SIZE = 32        # Nombre d'images traitées en même temps\n",
    "IMG_SIZE = 224         # Taille standard pour MobileNetV2 (224x224 pixels)\n",
    "EPOCHS = 10            # Nombre d'époques d'entraînement\n",
    "LEARNING_RATE = 0.0001 # Taux d'apprentissage initial\n",
    "\n",
    "print(\"📋 Configuration d'entraînement:\")\n",
    "print(f\"   • Taille de batch: {BATCH_SIZE}\")\n",
    "print(f\"   • Taille d'image: {IMG_SIZE}x{IMG_SIZE} pixels\")\n",
    "print(f\"   • Nombre d'époques: {EPOCHS}\")\n",
    "print(f\"   • Taux d'apprentissage: {LEARNING_RATE}\")\n",
    "\n",
    "# Explication pédagogique\n",
    "print(\"\\n🎓 Explication des paramètres:\")\n",
    "print(\"   🔹 BATCH_SIZE: Plus il est grand, plus l'entraînement est stable mais consomme plus de mémoire\")\n",
    "print(\"   🔹 IMG_SIZE: Doit correspondre à la taille attendue par le modèle pré-entraîné\")\n",
    "print(\"   🔹 LEARNING_RATE: Petit pour le fine-tuning pour éviter de 'casser' les features pré-entraînées\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌺 Chargement des Données - Dataset tf_flowers\n",
    "\n",
    "Nous allons utiliser le dataset **tf_flowers** qui contient des images de 5 types de fleurs différentes.\n",
    "\n",
    "### 📊 Qu'est-ce que tf_flowers ?\n",
    "\n",
    "- **5 classes** de fleurs : daisy, dandelion, roses, sunflowers, tulips\n",
    "- **~3700 images** au total\n",
    "- **Images de tailles variables** (nous les redimensionnerons)\n",
    "- **Dataset supervisé** (chaque image a son label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🌸 Chargement du dataset tf_flowers\n",
    "print(\"📥 Téléchargement du dataset tf_flowers...\")\n",
    "print(\"(Cela peut prendre quelques minutes la première fois)\\n\")\n",
    "\n",
    "dataset_name = \"tf_flowers\"\n",
    "(ds_train, ds_val), ds_info = tfds.load(\n",
    "    dataset_name,\n",
    "    split=['train[:80%]', 'train[80%:]'],  # 80% pour l'entraînement, 20% pour la validation\n",
    "    with_info=True,\n",
    "    as_supervised=True  # Retourne (image, label) directement\n",
    ")\n",
    "\n",
    "# 📊 Informations sur le dataset\n",
    "num_classes = ds_info.features['label'].num_classes\n",
    "class_names = ds_info.features['label'].names\n",
    "\n",
    "print(f\"✅ Dataset chargé avec succès !\")\n",
    "print(f\"📈 Nombre de classes: {num_classes}\")\n",
    "print(f\"🏷️ Noms des classes: {class_names}\")\n",
    "print(f\"📊 Total d'exemples: {ds_info.splits['train'].num_examples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔍 Exploration du Dataset\n",
    "\n",
    "Regardons la répartition des données et comprenons la structure :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Compter les échantillons dans chaque split\n",
    "train_size = sum(1 for _ in ds_train)\n",
    "val_size = sum(1 for _ in ds_val)\n",
    "\n",
    "print(\"📋 Répartition des données:\")\n",
    "print(f\"   🎯 Entraînement: {train_size} images ({train_size/(train_size+val_size)*100:.1f}%)\")\n",
    "print(f\"   ✅ Validation: {val_size} images ({val_size/(train_size+val_size)*100:.1f}%)\")\n",
    "print(f\"   📊 Total: {train_size + val_size} images\")\n",
    "\n",
    "# 🖼️ Examiner une image d'exemple\n",
    "print(\"\\n🔍 Exemple d'image du dataset:\")\n",
    "for image, label in ds_train.take(1):\n",
    "    print(f\"   📐 Forme de l'image: {image.shape}\")\n",
    "    print(f\"   🎨 Type de données: {image.dtype}\")\n",
    "    print(f\"   🏷️ Label: {label.numpy()} ({class_names[label.numpy()]})\")\n",
    "    print(f\"   📊 Valeurs pixel min/max: {tf.reduce_min(image).numpy()}/{tf.reduce_max(image).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🛠️ Préparation des Données\n",
    "\n",
    "Avant d'entraîner notre modèle, nous devons préparer nos données :\n",
    "\n",
    "1. **Redimensionner** les images à 224x224 (taille attendue par MobileNetV2)\n",
    "2. **Normaliser** les pixels selon MobileNetV2\n",
    "3. **Augmenter** les données d'entraînement\n",
    "4. **Optimiser** les performances avec batching et prefetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 Fonction de préprocessing\n",
    "def preprocess_image(image, label):\n",
    "    \"\"\"\n",
    "    Préprocesse une image pour MobileNetV2\n",
    "    \n",
    "    Args:\n",
    "        image: Tensor d'image (hauteur, largeur, 3)\n",
    "        label: Label de l'image\n",
    "    \n",
    "    Returns:\n",
    "        image: Image préprocessée (224, 224, 3)\n",
    "        label: Label inchangé\n",
    "    \"\"\"\n",
    "    # ✂️ Redimensionnement à 224x224\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    \n",
    "    # 🎨 Préprocessing spécifique à MobileNetV2\n",
    "    # Convertit les pixels de [0, 255] vers [-1, 1]\n",
    "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "print(\"✅ Fonction de préprocessing définie\")\n",
    "print(\"   🔄 Redimensionnement: Variable → 224x224\")\n",
    "print(\"   📊 Normalisation: [0, 255] → [-1, 1]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎲 Data Augmentation\n",
    "\n",
    "L'augmentation de données aide à améliorer la généralisation en créant des variations des images d'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎲 Couches d'augmentation de données\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),        # Retournement horizontal aléatoire\n",
    "    layers.RandomRotation(0.2),             # Rotation aléatoire ±20%\n",
    "    layers.RandomZoom(0.1),                 # Zoom aléatoire ±10%\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "def augment_image(image, label):\n",
    "    \"\"\"\n",
    "    Applique l'augmentation de données pendant l'entraînement\n",
    "    \"\"\"\n",
    "    image = data_augmentation(image, training=True)\n",
    "    return image, label\n",
    "\n",
    "print(\"🎲 Augmentation de données configurée:\")\n",
    "print(\"   ↔️ Retournement horizontal aléatoire\")\n",
    "print(\"   🔄 Rotation aléatoire (±36°)\")\n",
    "print(\"   🔍 Zoom aléatoire (±10%)\")\n",
    "print(\"\\n💡 Pourquoi augmenter les données ?\")\n",
    "print(\"   • Augmente artificiellement la taille du dataset\")\n",
    "print(\"   • Améliore la généralisation du modèle\")\n",
    "print(\"   • Réduit le surapprentissage (overfitting)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📊 Application du Pipeline de Données\n",
    "\n",
    "Maintenant, appliquons toutes nos transformations aux datasets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚡ Configuration pour l'optimisation des performances\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "print(\"🔧 Application du pipeline de préparation des données...\\n\")\n",
    "\n",
    "# 🎯 Dataset d'entraînement avec augmentation\n",
    "print(\"📋 Pipeline d'entraînement:\")\n",
    "ds_train_processed = ds_train.map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "print(\"   ✅ 1. Préprocessing appliqué\")\n",
    "\n",
    "ds_train_processed = ds_train_processed.map(augment_image, num_parallel_calls=AUTOTUNE)\n",
    "print(\"   ✅ 2. Augmentation appliquée\")\n",
    "\n",
    "ds_train_processed = ds_train_processed.batch(BATCH_SIZE)\n",
    "print(\"   ✅ 3. Batching appliqué\")\n",
    "\n",
    "ds_train_processed = ds_train_processed.prefetch(AUTOTUNE)\n",
    "print(\"   ✅ 4. Prefetching appliqué\")\n",
    "\n",
    "# 🎯 Dataset de validation SANS augmentation\n",
    "print(\"\\n📋 Pipeline de validation:\")\n",
    "ds_val_processed = ds_val.map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "print(\"   ✅ 1. Préprocessing appliqué (SANS augmentation)\")\n",
    "\n",
    "ds_val_processed = ds_val_processed.batch(BATCH_SIZE)\n",
    "print(\"   ✅ 2. Batching appliqué\")\n",
    "\n",
    "ds_val_processed = ds_val_processed.prefetch(AUTOTUNE)\n",
    "print(\"   ✅ 3. Prefetching appliqué\")\n",
    "\n",
    "print(\"\\n💡 Pourquoi pas d'augmentation en validation ?\")\n",
    "print(\"   • La validation doit être reproductible\")\n",
    "print(\"   • Nous voulons évaluer sur les données 'réelles'\")\n",
    "print(\"   • L'augmentation ne sert qu'à enrichir l'entraînement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎨 Visualisation des Données\n",
    "\n",
    "Visualisons nos données avant et après préprocessing pour bien comprendre les transformations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dataset, title=\"Batch d'images\", num_images=9, figsize=(12, 12)):\n",
    "    \"\"\"\n",
    "    Visualise un batch d'images avec leurs labels\n",
    "    \n",
    "    Args:\n",
    "        dataset: Dataset TensorFlow\n",
    "        title: Titre du graphique\n",
    "        num_images: Nombre d'images à afficher\n",
    "        figsize: Taille de la figure\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for images, labels in dataset.take(1):\n",
    "        for i in range(min(num_images, len(images))):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            \n",
    "            # Récupérer et préparer l'image pour l'affichage\n",
    "            image = images[i].numpy()\n",
    "            \n",
    "            # Si l'image est normalisée [-1, 1], la ramener à [0, 1]\n",
    "            if image.min() < 0:\n",
    "                image = (image + 1) / 2\n",
    "            \n",
    "            # Si les valeurs sont > 1, normaliser\n",
    "            if image.max() > 1:\n",
    "                image = image / 255.0\n",
    "            \n",
    "            plt.imshow(image)\n",
    "            plt.title(f\"{class_names[labels[i]]}\", fontsize=12, pad=10)\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"🎨 Fonction de visualisation créée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🖼️ Images Originales\n",
    "\n",
    "Regardons d'abord les images telles qu'elles sont dans le dataset original :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🖼️ Fonction de redimensionnement simple pour la visualisation\n",
    "def resize_for_display(image, label):\n",
    "    \"\"\"Redimensionne uniquement pour l'affichage (pas de normalisation)\"\"\"\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    return image, label\n",
    "\n",
    "# 🖼️ Affichage des images originales (redimensionnées pour l'affichage)\n",
    "print(\"🌸 Aperçu des images originales du dataset:\")\n",
    "print(\"ℹ️ Note: Images redimensionnées à 224x224 pour permettre l'affichage en batch\")\n",
    "ds_train_display = ds_train.map(resize_for_display).batch(9)\n",
    "show_batch(ds_train_display, title=\"Images Originales (redimensionnées pour affichage)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔄 Images Après Préprocessing\n",
    "\n",
    "Maintenant, voyons les mêmes images après redimensionnement et normalisation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔄 Affichage après préprocessing (sans augmentation)\n",
    "ds_preprocessed_only = ds_train.map(preprocess_image).batch(9)\n",
    "print(\"🔧 Aperçu après préprocessing (redimensionnement + normalisation):\")\n",
    "show_batch(ds_preprocessed_only, title=\"Images Après Préprocessing (224x224, normalisées)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎲 Effet de l'Augmentation de Données\n",
    "\n",
    "Comparons la même image avant et après augmentation pour voir l'effet des transformations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎲 Démonstration de l'augmentation de données\n",
    "def show_augmentation_effect():\n",
    "    \"\"\"\n",
    "    Montre l'effet de l'augmentation sur une même image\n",
    "    \"\"\"\n",
    "    # Prendre une seule image\n",
    "    for original_image, label in ds_train.take(1):\n",
    "        # Préprocesser l'image\n",
    "        processed_image, _ = preprocess_image(original_image, label)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "        fig.suptitle(f\"Effet de l'Augmentation de Données - Classe: {class_names[label]}\", \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Image originale préprocessée\n",
    "        axes[0, 0].imshow((processed_image + 1) / 2)\n",
    "        axes[0, 0].set_title(\"Image Originale\\n(après préprocessing)\", fontweight='bold')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        # Générer plusieurs versions augmentées\n",
    "        for i in range(1, 4):\n",
    "            augmented_image, _ = augment_image(processed_image, label)\n",
    "            axes[0, i].imshow((augmented_image + 1) / 2)\n",
    "            axes[0, i].set_title(f\"Augmentation {i}\")\n",
    "            axes[0, i].axis('off')\n",
    "        \n",
    "        # Encore plus d'exemples\n",
    "        for i in range(4):\n",
    "            augmented_image, _ = augment_image(processed_image, label)\n",
    "            axes[1, i].imshow((augmented_image + 1) / 2)\n",
    "            axes[1, i].set_title(f\"Augmentation {i+4}\")\n",
    "            axes[1, i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        break\n",
    "\n",
    "print(\"🎲 Démonstration de l'augmentation de données:\")\n",
    "show_augmentation_effect()\n",
    "\n",
    "print(\"\\n💡 Observations sur l'augmentation:\")\n",
    "print(\"   🔄 Chaque version est légèrement différente\")\n",
    "print(\"   📊 Cela multiplie artificiellement notre dataset\")\n",
    "print(\"   🎯 Le modèle apprend à être plus robuste aux variations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📊 Aperçu Final des Données d'Entraînement\n",
    "\n",
    "Regardons maintenant un batch complet tel qu'il sera fourni au modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Affichage du dataset final d'entraînement\n",
    "print(\"🎯 Aperçu final du dataset d'entraînement (avec toutes les transformations):\")\n",
    "show_batch(ds_train_processed, title=\"Dataset d'Entraînement Final (préprocessé + augmenté)\")\n",
    "\n",
    "print(\"\\n📋 Résumé de ce que le modèle va recevoir:\")\n",
    "print(\"   📐 Taille: 224x224x3 pixels\")\n",
    "print(\"   📊 Valeurs: [-1, 1] (normalisées pour MobileNetV2)\")\n",
    "print(\"   🎲 Variété: Augmentées aléatoirement à chaque époque\")\n",
    "print(\"   📦 Batch: 32 images à la fois\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 Création du Modèle avec Transfer Learning\n",
    "\n",
    "Maintenant que nos données sont prêtes, créons notre modèle basé sur MobileNetV2 pré-entraîné.\n",
    "\n",
    "### 🎯 Qu'est-ce que MobileNetV2 ?\n",
    "\n",
    "- **Architecture légère** optimisée pour mobile\n",
    "- **Pré-entraîné sur ImageNet** (1.4M d'images, 1000 classes)\n",
    "- **Excellent équilibre** entre performance et vitesse\n",
    "- **Idéal pour le fine-tuning** sur de nouveaux domaines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧠 Chargement du modèle de base MobileNetV2\n",
    "print(\"🚀 Chargement de MobileNetV2 pré-entraîné...\")\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),  # Forme d'entrée\n",
    "    include_top=False,                    # Exclure la couche de classification finale\n",
    "    weights='imagenet'                    # Utiliser les poids pré-entraînés ImageNet\n",
    ")\n",
    "\n",
    "# 🔒 Geler les couches du modèle de base (transfer learning)\n",
    "base_model.trainable = False\n",
    "\n",
    "print(\"✅ MobileNetV2 chargé avec succès !\")\n",
    "print(f\"📊 Nombre de couches: {len(base_model.layers)}\")\n",
    "print(f\"📐 Forme de sortie: {base_model.output_shape}\")\n",
    "print(f\"🔒 Couches gelées: {not base_model.trainable}\")\n",
    "\n",
    "# 💡 Explication pédagogique\n",
    "print(\"\\n🎓 Pourquoi geler les couches ?\")\n",
    "print(\"   • Les features bas niveau (bords, textures) sont déjà bien apprises\")\n",
    "print(\"   • Évite de 'casser' les représentations pré-entraînées\")\n",
    "print(\"   • Accélère l'entraînement initial\")\n",
    "print(\"   • Nous dégelerons certaines couches plus tard (fine-tuning)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🏗️ Architecture Complète du Modèle\n",
    "\n",
    "Ajoutons nos propres couches au-dessus du modèle pré-entraîné :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🏗️ Construction du modèle complet\n",
    "print(\"🔧 Construction de l'architecture complète...\")\n",
    "\n",
    "# Couche d'entrée\n",
    "inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# Modèle de base (gelé)\n",
    "x = base_model(inputs, training=False)  # training=False pour utiliser en mode inférence\n",
    "\n",
    "# Pooling global pour réduire les dimensions\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Couche de dropout pour la régularisation\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "# Couche de classification finale\n",
    "outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Création du modèle final\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "print(\"✅ Modèle créé avec succès !\")\n",
    "\n",
    "# Calculer les paramètres de manière compatible TensorFlow\n",
    "total_params = model.count_params()\n",
    "trainable_params = sum(tf.size(var).numpy() for var in model.trainable_variables)\n",
    "frozen_params = total_params - trainable_params\n",
    "\n",
    "print(f\"📊 Nombre total de paramètres: {total_params:,}\")\n",
    "print(f\"🎯 Paramètres entraînables: {trainable_params:,}\")\n",
    "print(f\"🔒 Paramètres gelés: {frozen_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📋 Résumé de l'Architecture\n",
    "\n",
    "Visualisons l'architecture de notre modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📋 Affichage du résumé du modèle\n",
    "print(\"🏗️ Architecture du modèle:\")\n",
    "model.summary()\n",
    "\n",
    "print(\"\\n🎓 Explication de l'architecture:\")\n",
    "print(\"   📥 Input (224, 224, 3): Image d'entrée\")\n",
    "print(\"   🧠 MobileNetV2: Extraction de features (gelé)\")\n",
    "print(\"   🌐 GlobalAveragePooling2D: Réduction dimensionnelle\")\n",
    "print(\"   🎲 Dropout(0.2): Régularisation (20% de neurones désactivés)\")\n",
    "print(\"   🎯 Dense(5, softmax): Classification finale (5 classes de fleurs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Visualisation de l'Architecture\n",
    "\n",
    "Créons un diagramme pour mieux comprendre notre modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎨 Visualisation de l'architecture\n",
    "def visualize_model_architecture():\n",
    "    \"\"\"\n",
    "    Crée un diagramme explicatif de l'architecture\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 10))\n",
    "    \n",
    "    # Définir les composants et leurs positions\n",
    "    components = [\n",
    "        {\"name\": \"Image d'entrée\\n224×224×3\", \"pos\": (1, 8), \"color\": \"lightblue\", \"frozen\": False},\n",
    "        {\"name\": \"MobileNetV2\\n(Pré-entraîné)\\n🔒 GELÉ\", \"pos\": (1, 6), \"color\": \"lightcoral\", \"frozen\": True},\n",
    "        {\"name\": \"Features\\n7×7×1280\", \"pos\": (1, 4.5), \"color\": \"lightgreen\", \"frozen\": True},\n",
    "        {\"name\": \"GlobalAveragePooling2D\\n→ 1280\", \"pos\": (1, 3), \"color\": \"lightyellow\", \"frozen\": False},\n",
    "        {\"name\": \"Dropout(0.2)\\n🎲 Régularisation\", \"pos\": (1, 1.5), \"color\": \"lightpink\", \"frozen\": False},\n",
    "        {\"name\": \"Dense(5)\\n+ Softmax\\n🎯 Classification\", \"pos\": (1, 0), \"color\": \"lightsteelblue\", \"frozen\": False}\n",
    "    ]\n",
    "    \n",
    "    # Dessiner les composants\n",
    "    for i, comp in enumerate(components):\n",
    "        x, y = comp[\"pos\"]\n",
    "        \n",
    "        # Style différent pour les couches gelées\n",
    "        if comp[\"frozen\"]:\n",
    "            bbox_props = dict(boxstyle=\"round,pad=0.3\", facecolor=comp[\"color\"], \n",
    "                            edgecolor=\"red\", linewidth=2, linestyle=\"--\")\n",
    "        else:\n",
    "            bbox_props = dict(boxstyle=\"round,pad=0.3\", facecolor=comp[\"color\"], \n",
    "                            edgecolor=\"black\", linewidth=1)\n",
    "        \n",
    "        ax.text(x, y, comp[\"name\"], ha=\"center\", va=\"center\", \n",
    "               fontsize=12, fontweight=\"bold\", bbox=bbox_props)\n",
    "        \n",
    "        # Flèches entre composants\n",
    "        if i < len(components) - 1:\n",
    "            next_y = components[i+1][\"pos\"][1]\n",
    "            ax.annotate(\"\", xy=(x, next_y + 0.4), xytext=(x, y - 0.4),\n",
    "                       arrowprops=dict(arrowstyle=\"->\", lw=2, color=\"darkblue\"))\n",
    "    \n",
    "    # Annotations explicatives\n",
    "    ax.text(3, 6, \"Phase 1: Transfer Learning\\n• Couches gelées\\n• Apprentissage rapide\\n• Features génériques\", \n",
    "           fontsize=11, bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"wheat\", alpha=0.8))\n",
    "    \n",
    "    ax.text(3, 2, \"Phase 2: Fine-Tuning\\n• Dégel partiel\\n• Apprentissage lent\\n• Adaptation spécifique\", \n",
    "           fontsize=11, bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightcyan\", alpha=0.8))\n",
    "    \n",
    "    # Configuration des axes\n",
    "    ax.set_xlim(-0.5, 5)\n",
    "    ax.set_ylim(-1, 9)\n",
    "    ax.set_title(\"Architecture du Modèle de Fine-Tuning\", fontsize=16, fontweight=\"bold\", pad=20)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Légende\n",
    "    legend_elements = [\n",
    "        plt.Rectangle((0, 0), 1, 1, facecolor='lightcoral', edgecolor='red', linestyle='--', label='Couches gelées'),\n",
    "        plt.Rectangle((0, 0), 1, 1, facecolor='lightsteelblue', edgecolor='black', label='Couches entraînables')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"🎨 Visualisation de l'architecture du modèle:\")\n",
    "visualize_model_architecture()\n",
    "\n",
    "print(\"\\n💡 Points clés de l'architecture:\")\n",
    "print(\"   🔒 MobileNetV2 gelé: Préserve les features pré-apprises\")\n",
    "print(\"   🎯 Nouvelles couches: Adaptées à notre problème (5 classes)\")\n",
    "print(\"   ⚡ Efficace: Peu de paramètres à entraîner initialement\")\n",
    "print(\"   🎲 Régularisation: Dropout pour éviter l'overfitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Phase 1 : Transfer Learning (Couches Gelées)\n",
    "\n",
    "Nous allons maintenant entraîner notre modèle en deux phases :\n",
    "\n",
    "1. **Phase 1** : Transfer Learning avec couches gelées\n",
    "2. **Phase 2** : Fine-Tuning avec dégel partiel\n",
    "\n",
    "### 🔒 Pourquoi Commencer avec les Couches Gelées ?\n",
    "\n",
    "- ⚡ **Entraînement rapide** : Moins de paramètres à mettre à jour\n",
    "- 🛡️ **Préservation des features** : Évite de \"casser\" les représentations pré-apprises\n",
    "- 🎯 **Adaptation douce** : Les nouvelles couches apprennent d'abord à utiliser les features existantes\n",
    "- 💾 **Économie de ressources** : Moins de mémoire et calculs nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚙️ Configuration de l'entraînement Phase 1\n",
    "print(\"🎯 === PHASE 1: TRANSFER LEARNING (couches gelées) ===\")\n",
    "print(\"\\n🔧 Configuration de l'optimiseur et des métriques...\")\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='sparse_categorical_crossentropy',  # Pour labels entiers (0, 1, 2, 3, 4)\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"✅ Modèle compilé !\")\n",
    "print(f\"   🧠 Optimiseur: Adam (lr={LEARNING_RATE})\")\n",
    "print(f\"   📊 Fonction de perte: Sparse Categorical Crossentropy\")\n",
    "print(f\"   📈 Métriques: Accuracy\")\n",
    "\n",
    "# 🎓 Explication pédagogique\n",
    "print(\"\\n🎓 Pourquoi ces choix ?\")\n",
    "print(\"   • Adam: Optimiseur adaptatif, bon pour la plupart des cas\")\n",
    "print(\"   • Sparse Categorical: Nos labels sont des entiers (0,1,2,3,4)\")\n",
    "print(\"   • Learning rate faible: Pour ne pas perturber les features pré-entraînées\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📊 Callbacks pour l'Entraînement\n",
    "\n",
    "Les callbacks nous aident à surveiller et contrôler l'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 Configuration des callbacks\n",
    "callbacks = [\n",
    "    # Réduction du learning rate si la perte stagne\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',           # Surveiller la perte de validation\n",
    "        factor=0.2,                   # Diviser le LR par 5 (×0.2)\n",
    "        patience=3,                   # Attendre 3 époques sans amélioration\n",
    "        min_lr=1e-7,                  # LR minimum\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Arrêt anticipé si pas d'amélioration\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',           # Surveiller la perte de validation\n",
    "        patience=5,                   # Attendre 5 époques sans amélioration\n",
    "        restore_best_weights=True,    # Restaurer les meilleurs poids\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"🔧 Callbacks configurés:\")\n",
    "print(\"   📉 ReduceLROnPlateau: Réduit automatiquement le learning rate\")\n",
    "print(\"   ⏹️ EarlyStopping: Arrête l'entraînement si pas d'amélioration\")\n",
    "print(\"\\n💡 Avantages des callbacks:\")\n",
    "print(\"   • Évitent le surapprentissage\")\n",
    "print(\"   • Économisent du temps de calcul\")\n",
    "print(\"   • Trouvent automatiquement les meilleurs hyperparamètres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🚀 Lancement de l'Entraînement Phase 1\n",
    "\n",
    "C'est parti pour la première phase d'entraînement !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 Entraînement Phase 1\n",
    "print(\"🚀 Début de l'entraînement Phase 1...\")\n",
    "print(f\"📊 {sum(1 for _ in ds_train_processed)} batches d'entraînement\")\n",
    "print(f\"📊 {sum(1 for _ in ds_val_processed)} batches de validation\")\n",
    "print(\"\\n⏰ Cela peut prendre quelques minutes...\\n\")\n",
    "\n",
    "# Entraînement\n",
    "history = model.fit(\n",
    "    ds_train_processed,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=ds_val_processed,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n🎉 Phase 1 terminée !\")\n",
    "print(f\"✅ Nombre d'époques effectuées: {len(history.history['accuracy'])}\")\n",
    "print(f\"📈 Précision finale d'entraînement: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"📊 Précision finale de validation: {history.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔓 Phase 2 : Fine-Tuning (Dégel Partiel)\n",
    "\n",
    "Maintenant que notre modèle a appris à utiliser les features de MobileNetV2, nous allons **dégeler** certaines couches pour un ajustement plus fin.\n",
    "\n",
    "### 🎯 Stratégie de Dégel\n",
    "\n",
    "- 🔓 **Dégeler les dernières couches** : Elles contiennent les features plus spécifiques\n",
    "- 🔒 **Garder gelées les premières couches** : Elles contiennent les features génériques (bords, textures)\n",
    "- 📉 **Réduire le learning rate** : Pour des ajustements plus fins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 Analyse des couches de MobileNetV2\n",
    "print(\"🔍 Analyse des couches de MobileNetV2:\")\n",
    "print(f\"📊 Nombre total de couches: {len(base_model.layers)}\")\n",
    "\n",
    "# Afficher quelques couches pour comprendre la structure\n",
    "print(\"\\n🏗️ Structure des couches (dernières 10):\")\n",
    "for i, layer in enumerate(base_model.layers[-10:]):\n",
    "    print(f\"   {len(base_model.layers)-10+i:3d}: {layer.name} ({layer.__class__.__name__})\")\n",
    "\n",
    "# 🔓 Stratégie de dégel : dégeler les 20 dernières couches\n",
    "fine_tune_at = len(base_model.layers) - 20\n",
    "\n",
    "print(f\"\\n🎯 Stratégie de dégel:\")\n",
    "print(f\"   🔒 Couches 0 à {fine_tune_at-1}: GELÉES (features génériques)\")\n",
    "print(f\"   🔓 Couches {fine_tune_at} à {len(base_model.layers)-1}: DÉGELÉES (features spécifiques)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔓 Application du dégel\n",
    "print(\"🔧 Application de la stratégie de dégel...\")\n",
    "\n",
    "# Dégeler le modèle de base\n",
    "base_model.trainable = True\n",
    "\n",
    "# Geler les premières couches, dégeler les dernières\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    if i < fine_tune_at:\n",
    "        layer.trainable = False  # Garder gelé\n",
    "    else:\n",
    "        layer.trainable = True   # Dégeler\n",
    "\n",
    "# Compter les paramètres entraînables\n",
    "trainable_params = sum(tf.size(var).numpy() for var in model.trainable_variables)\n",
    "total_params = model.count_params()\n",
    "\n",
    "print(\"✅ Dégel appliqué !\")\n",
    "print(f\"📊 Paramètres entraînables: {trainable_params:,} ({trainable_params/total_params*100:.1f}%)\")\n",
    "print(f\"🔒 Paramètres gelés: {total_params-trainable_params:,} ({(total_params-trainable_params)/total_params*100:.1f}%)\")\n",
    "print(f\"📈 Total: {total_params:,} paramètres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚙️ Recompilation avec Learning Rate Réduit\n",
    "\n",
    "Pour le fine-tuning, nous utilisons un learning rate plus faible :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚙️ Recompilation avec learning rate réduit\n",
    "fine_tune_lr = LEARNING_RATE / 10  # Diviser par 10\n",
    "\n",
    "print(f\"🔧 Recompilation du modèle pour le fine-tuning...\")\n",
    "print(f\"📉 Nouveau learning rate: {fine_tune_lr} (10x plus faible)\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=fine_tune_lr),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"✅ Modèle recompilé !\")\n",
    "print(\"\\n💡 Pourquoi un learning rate plus faible ?\")\n",
    "print(\"   • Les features pré-entraînées sont déjà bonnes\")\n",
    "print(\"   • On veut des ajustements fins, pas des changements drastiques\")\n",
    "print(\"   • Évite de 'casser' ce qui a été appris en Phase 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🚀 Lancement du Fine-Tuning\n",
    "\n",
    "Continuons l'entraînement avec les couches dégelées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 Entraînement Phase 2 (Fine-tuning)\n",
    "print(\"🚀 === PHASE 2: FINE-TUNING (couches dégelées) ===\")\n",
    "print(\"\\n⏰ Début du fine-tuning...\")\n",
    "\n",
    "# Continuer l'entraînement depuis la dernière époque\n",
    "initial_epoch = len(history.history['accuracy'])\n",
    "total_epochs = initial_epoch + EPOCHS\n",
    "\n",
    "print(f\"📊 Reprendre depuis l'époque: {initial_epoch}\")\n",
    "print(f\"🎯 Aller jusqu'à l'époque: {total_epochs}\")\n",
    "print(f\"➕ Époque supplémentaires: {EPOCHS}\")\n",
    "\n",
    "# Fine-tuning\n",
    "history_fine = model.fit(\n",
    "    ds_train_processed,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=initial_epoch,\n",
    "    validation_data=ds_val_processed,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n🎉 Fine-tuning terminé !\")\n",
    "print(f\"✅ Époques totales effectuées: {len(history.history['accuracy']) + len(history_fine.history['accuracy'])}\")\n",
    "print(f\"📈 Précision finale d'entraînement: {history_fine.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"📊 Précision finale de validation: {history_fine.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Visualisation des Résultats d'Entraînement\n",
    "\n",
    "Analysons maintenant les performances de notre modèle à travers les deux phases d'entraînement.\n",
    "\n",
    "### 📈 Importance de la Visualisation\n",
    "\n",
    "Les graphiques nous permettent de :\n",
    "- **Détecter le surapprentissage** (overfitting)\n",
    "- **Comprendre l'évolution** de l'apprentissage\n",
    "- **Valider l'efficacité** du fine-tuning\n",
    "- **Identifier les problèmes** potentiels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history1, history2=None, title=\"Évolution de l'Entraînement\"):\n",
    "    \"\"\"\n",
    "    Affiche les courbes d'entraînement pour les deux phases\n",
    "    \n",
    "    Args:\n",
    "        history1: Historique de la Phase 1 (Transfer Learning)\n",
    "        history2: Historique de la Phase 2 (Fine-Tuning) - optionnel\n",
    "        title: Titre du graphique\n",
    "    \"\"\"\n",
    "    # Préparer les données\n",
    "    if history2:\n",
    "        # Combiner les deux phases\n",
    "        acc = history1.history['accuracy'] + history2.history['accuracy']\n",
    "        val_acc = history1.history['val_accuracy'] + history2.history['val_accuracy']\n",
    "        loss = history1.history['loss'] + history2.history['loss']\n",
    "        val_loss = history1.history['val_loss'] + history2.history['val_loss']\n",
    "        \n",
    "        # Point de transition entre les phases\n",
    "        transition_point = len(history1.history['accuracy']) - 1\n",
    "        \n",
    "        phases_info = True\n",
    "    else:\n",
    "        # Une seule phase\n",
    "        acc = history1.history['accuracy']\n",
    "        val_acc = history1.history['val_accuracy']\n",
    "        loss = history1.history['loss']\n",
    "        val_loss = history1.history['val_loss']\n",
    "        \n",
    "        phases_info = False\n",
    "    \n",
    "    epochs_range = range(len(acc))\n",
    "    \n",
    "    # Créer la figure avec 2 sous-graphiques\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    fig.suptitle(title, fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Graphique 1: Précision\n",
    "    ax1.plot(epochs_range, acc, 'b-', label='Entraînement', linewidth=2)\n",
    "    ax1.plot(epochs_range, val_acc, 'r-', label='Validation', linewidth=2)\n",
    "    \n",
    "    if phases_info:\n",
    "        # Ligne de séparation entre les phases\n",
    "        ax1.axvline(x=transition_point, color='green', linestyle='--', \n",
    "                   linewidth=2, label='Début Fine-Tuning')\n",
    "        \n",
    "        # Zones colorées pour les phases\n",
    "        ax1.axvspan(0, transition_point, alpha=0.1, color='blue', label='Phase 1: Transfer Learning')\n",
    "        ax1.axvspan(transition_point, len(acc)-1, alpha=0.1, color='orange', label='Phase 2: Fine-Tuning')\n",
    "    \n",
    "    ax1.set_title('📈 Évolution de la Précision', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Époques')\n",
    "    ax1.set_ylabel('Précision')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Graphique 2: Perte\n",
    "    ax2.plot(epochs_range, loss, 'b-', label='Entraînement', linewidth=2)\n",
    "    ax2.plot(epochs_range, val_loss, 'r-', label='Validation', linewidth=2)\n",
    "    \n",
    "    if phases_info:\n",
    "        # Ligne de séparation entre les phases\n",
    "        ax2.axvline(x=transition_point, color='green', linestyle='--', \n",
    "                   linewidth=2, label='Début Fine-Tuning')\n",
    "        \n",
    "        # Zones colorées pour les phases\n",
    "        ax2.axvspan(0, transition_point, alpha=0.1, color='blue', label='Phase 1: Transfer Learning')\n",
    "        ax2.axvspan(transition_point, len(loss)-1, alpha=0.1, color='orange', label='Phase 2: Fine-Tuning')\n",
    "    \n",
    "    ax2.set_title('📉 Évolution de la Perte', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Époques')\n",
    "    ax2.set_ylabel('Perte')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistiques finales\n",
    "    print(\"\\n📊 Statistiques finales:\")\n",
    "    print(f\"   🎯 Précision finale (entraînement): {acc[-1]:.4f} ({acc[-1]*100:.2f}%)\")\n",
    "    print(f\"   ✅ Précision finale (validation): {val_acc[-1]:.4f} ({val_acc[-1]*100:.2f}%)\")\n",
    "    print(f\"   📉 Perte finale (entraînement): {loss[-1]:.4f}\")\n",
    "    print(f\"   📊 Perte finale (validation): {val_loss[-1]:.4f}\")\n",
    "    \n",
    "    if phases_info:\n",
    "        print(f\"\\n📈 Amélioration grâce au fine-tuning:\")\n",
    "        print(f\"   • Précision validation: {val_acc[transition_point]:.4f} → {val_acc[-1]:.4f} \"\n",
    "              f\"(+{(val_acc[-1] - val_acc[transition_point])*100:.2f}%)\")\n",
    "        print(f\"   • Perte validation: {val_loss[transition_point]:.4f} → {val_loss[-1]:.4f} \"\n",
    "              f\"({((val_loss[-1] - val_loss[transition_point])/val_loss[transition_point])*100:+.2f}%)\")\n",
    "\n",
    "print(\"📊 Fonction de visualisation des résultats créée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📈 Visualisation des Performances\n",
    "\n",
    "Affichons maintenant les résultats de nos deux phases d'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Affichage des courbes de performance\n",
    "print(\"📈 Visualisation des résultats d'entraînement:\")\n",
    "plot_training_history(history, history_fine, \"🌸 Résultats du Fine-Tuning - Classification de Fleurs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔍 Analyse des Résultats\n",
    "\n",
    "Analysons ce que nous disent ces graphiques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 Analyse automatique des résultats\n",
    "def analyze_training_results(history1, history2=None):\n",
    "    \"\"\"\n",
    "    Analyse automatique des résultats d'entraînement\n",
    "    \"\"\"\n",
    "    print(\"🔍 === ANALYSE DES RÉSULTATS D'ENTRAÎNEMENT ===\")\n",
    "    \n",
    "    if history2:\n",
    "        # Analyse avec fine-tuning\n",
    "        val_acc_phase1 = history1.history['val_accuracy'][-1]\n",
    "        val_acc_phase2 = history2.history['val_accuracy'][-1]\n",
    "        improvement = val_acc_phase2 - val_acc_phase1\n",
    "        \n",
    "        print(f\"\\n📋 Comparaison des phases:\")\n",
    "        print(f\"   Phase 1 (Transfer Learning): {val_acc_phase1:.4f} ({val_acc_phase1*100:.2f}%)\")\n",
    "        print(f\"   Phase 2 (Fine-Tuning): {val_acc_phase2:.4f} ({val_acc_phase2*100:.2f}%)\")\n",
    "        print(f\"   🚀 Amélioration: +{improvement:.4f} (+{improvement*100:.2f}%)\")\n",
    "        \n",
    "        # Évaluation de l'amélioration\n",
    "        if improvement > 0.02:\n",
    "            print(\"   ✅ Excellent ! Le fine-tuning a significativement amélioré les performances\")\n",
    "        elif improvement > 0.01:\n",
    "            print(\"   👍 Bien ! Le fine-tuning a apporté une amélioration notable\")\n",
    "        elif improvement > 0:\n",
    "            print(\"   📈 Le fine-tuning a légèrement amélioré les performances\")\n",
    "        else:\n",
    "            print(\"   ⚠️ Le fine-tuning n'a pas amélioré les performances (possible surapprentissage)\")\n",
    "    \n",
    "    # Analyse du surapprentissage\n",
    "    final_history = history2 if history2 else history1\n",
    "    train_acc = final_history.history['accuracy'][-1]\n",
    "    val_acc = final_history.history['val_accuracy'][-1]\n",
    "    gap = train_acc - val_acc\n",
    "    \n",
    "    print(f\"\\n🎯 Analyse du surapprentissage:\")\n",
    "    print(f\"   Précision entraînement: {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "    print(f\"   Précision validation: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "    print(f\"   Écart: {gap:.4f} ({gap*100:.2f}%)\")\n",
    "    \n",
    "    if gap < 0.05:\n",
    "        print(\"   ✅ Excellent équilibre ! Pas de surapprentissage détecté\")\n",
    "    elif gap < 0.10:\n",
    "        print(\"   👍 Bon équilibre, léger surapprentissage acceptable\")\n",
    "    elif gap < 0.15:\n",
    "        print(\"   ⚠️ Surapprentissage modéré - pourrait être amélioré\")\n",
    "    else:\n",
    "        print(\"   🚨 Surapprentissage important - réviser la régularisation\")\n",
    "    \n",
    "    # Recommandations\n",
    "    print(f\"\\n💡 Recommandations:\")\n",
    "    if gap > 0.10:\n",
    "        print(\"   • Augmenter le dropout\")\n",
    "        print(\"   • Ajouter plus d'augmentation de données\")\n",
    "        print(\"   • Réduire le learning rate\")\n",
    "        print(\"   • Utiliser l'early stopping plus agressivement\")\n",
    "    \n",
    "    if val_acc < 0.80:\n",
    "        print(\"   • Essayer un modèle plus large (ResNet, EfficientNet)\")\n",
    "        print(\"   • Augmenter le nombre d'époques\")\n",
    "        print(\"   • Dégeler plus de couches\")\n",
    "    \n",
    "    if val_acc > 0.90:\n",
    "        print(\"   • Excellents résultats ! Le modèle est prêt pour la production\")\n",
    "        print(\"   • Considérer tester sur un dataset externe\")\n",
    "\n",
    "# Lancer l'analyse\n",
    "analyze_training_results(history, history_fine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📊 Métriques Détaillées par Époque\n",
    "\n",
    "Regardons l'évolution détaillée des métriques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Tableau détaillé des métriques\n",
    "import pandas as pd\n",
    "\n",
    "def create_metrics_table(history1, history2=None):\n",
    "    \"\"\"\n",
    "    Crée un tableau détaillé des métriques par époque\n",
    "    \"\"\"\n",
    "    # Préparer les données\n",
    "    if history2:\n",
    "        # Combiner les historiques\n",
    "        epochs = list(range(1, len(history1.history['accuracy']) + 1))\n",
    "        epochs.extend(range(len(history1.history['accuracy']) + 1, \n",
    "                          len(history1.history['accuracy']) + len(history2.history['accuracy']) + 1))\n",
    "        \n",
    "        train_acc = history1.history['accuracy'] + history2.history['accuracy']\n",
    "        val_acc = history1.history['val_accuracy'] + history2.history['val_accuracy']\n",
    "        train_loss = history1.history['loss'] + history2.history['loss']\n",
    "        val_loss = history1.history['val_loss'] + history2.history['val_loss']\n",
    "        \n",
    "        # Marquer les phases\n",
    "        phases = ['Transfer Learning'] * len(history1.history['accuracy'])\n",
    "        phases.extend(['Fine-Tuning'] * len(history2.history['accuracy']))\n",
    "    else:\n",
    "        epochs = list(range(1, len(history1.history['accuracy']) + 1))\n",
    "        train_acc = history1.history['accuracy']\n",
    "        val_acc = history1.history['val_accuracy']\n",
    "        train_loss = history1.history['loss']\n",
    "        val_loss = history1.history['val_loss']\n",
    "        phases = ['Training'] * len(history1.history['accuracy'])\n",
    "    \n",
    "    # Créer le DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Époque': epochs,\n",
    "        'Phase': phases,\n",
    "        'Précision Train': [f\"{acc:.4f}\" for acc in train_acc],\n",
    "        'Précision Val': [f\"{acc:.4f}\" for acc in val_acc],\n",
    "        'Perte Train': [f\"{loss:.4f}\" for loss in train_loss],\n",
    "        'Perte Val': [f\"{loss:.4f}\" for loss in val_loss],\n",
    "        'Écart Précision': [f\"{train_acc[i] - val_acc[i]:.4f}\" for i in range(len(train_acc))]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Créer et afficher le tableau\n",
    "print(\"📋 Tableau détaillé des métriques:\")\n",
    "metrics_df = create_metrics_table(history, history_fine)\n",
    "print(metrics_df.to_string(index=False))\n",
    "\n",
    "# Statistiques résumées\n",
    "print(\"\\n📊 Statistiques résumées:\")\n",
    "phase1_df = metrics_df[metrics_df['Phase'] == 'Transfer Learning']\n",
    "phase2_df = metrics_df[metrics_df['Phase'] == 'Fine-Tuning']\n",
    "\n",
    "if len(phase2_df) > 0:\n",
    "    print(f\"Phase 1 - Meilleure précision validation: {phase1_df['Précision Val'].max()}\")\n",
    "    print(f\"Phase 2 - Meilleure précision validation: {phase2_df['Précision Val'].max()}\")\n",
    "    print(f\"Amélioration totale: {float(phase2_df['Précision Val'].iloc[-1]) - float(phase1_df['Précision Val'].iloc[-1]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Évaluation et Prédictions du Modèle\n",
    "\n",
    "Maintenant que notre modèle est entraîné, évaluons ses performances et voyons comment il fait des prédictions sur de nouvelles images.\n",
    "\n",
    "### 📊 Pourquoi Évaluer ?\n",
    "\n",
    "L'évaluation nous permet de :\n",
    "- **Mesurer les performances réelles** sur des données non vues\n",
    "- **Identifier les erreurs** de classification\n",
    "- **Comprendre les forces et faiblesses** du modèle\n",
    "- **Valider l'utilisabilité** en production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Évaluation finale du modèle\n",
    "print(\"🎯 === ÉVALUATION FINALE DU MODÈLE ===\")\n",
    "print(\"\\n📋 Évaluation sur le dataset de validation...\")\n",
    "\n",
    "# Évaluation détaillée\n",
    "test_loss, test_acc = model.evaluate(ds_val_processed, verbose=1)\n",
    "\n",
    "print(f\"\\n✅ Résultats finaux:\")\n",
    "print(f\"   📉 Perte finale: {test_loss:.4f}\")\n",
    "print(f\"   🎯 Précision finale: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "\n",
    "# Interprétation des résultats\n",
    "if test_acc >= 0.95:\n",
    "    print(\"   🌟 Excellente performance ! Modèle prêt pour la production\")\n",
    "elif test_acc >= 0.90:\n",
    "    print(\"   🎉 Très bonne performance ! Résultats impressionnants\")\n",
    "elif test_acc >= 0.80:\n",
    "    print(\"   👍 Bonne performance, utilisable dans la plupart des cas\")\n",
    "elif test_acc >= 0.70:\n",
    "    print(\"   📈 Performance correcte, peut être améliorée\")\n",
    "else:\n",
    "    print(\"   ⚠️ Performance à améliorer, réviser l'approche\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔍 Analyse des Prédictions\n",
    "\n",
    "Regardons comment notre modèle fait ses prédictions sur des exemples concrets :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_show(dataset, model, num_images=9, figsize=(15, 15)):\n",
    "    \"\"\"\n",
    "    Affiche des prédictions du modèle avec analyse détaillée\n",
    "    \n",
    "    Args:\n",
    "        dataset: Dataset de validation\n",
    "        model: Modèle entraîné\n",
    "        num_images: Nombre d'images à afficher\n",
    "        figsize: Taille de la figure\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.suptitle(\"🔍 Prédictions du Modèle - Classification de Fleurs\", \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Statistiques pour l'analyse\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    confidence_scores = []\n",
    "    \n",
    "    for images, labels in dataset.take(1):\n",
    "        # Faire les prédictions\n",
    "        predictions = model.predict(images, verbose=0)\n",
    "        \n",
    "        for i in range(min(num_images, len(images))):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            \n",
    "            # Préparer l'image pour l'affichage\n",
    "            image = images[i].numpy()\n",
    "            # Dénormaliser de [-1, 1] vers [0, 1]\n",
    "            image = (image + 1) / 2\n",
    "            plt.imshow(image)\n",
    "            \n",
    "            # Analyser la prédiction\n",
    "            pred_probs = predictions[i]\n",
    "            pred_label = np.argmax(pred_probs)\n",
    "            true_label = labels[i].numpy()\n",
    "            confidence = pred_probs[pred_label]\n",
    "            \n",
    "            # Statistiques\n",
    "            total_predictions += 1\n",
    "            confidence_scores.append(confidence)\n",
    "            if pred_label == true_label:\n",
    "                correct_predictions += 1\n",
    "            \n",
    "            # Couleur selon la justesse de la prédiction\n",
    "            color = 'green' if pred_label == true_label else 'red'\n",
    "            \n",
    "            # Titre avec informations détaillées\n",
    "            true_name = class_names[true_label]\n",
    "            pred_name = class_names[pred_label]\n",
    "            \n",
    "            title = f\"✅ Vrai: {true_name}\\n🎯 Prédit: {pred_name}\\n📊 Confiance: {confidence:.3f}\"\n",
    "            if pred_label != true_label:\n",
    "                title = f\"❌ Vrai: {true_name}\\n🎯 Prédit: {pred_name}\\n📊 Confiance: {confidence:.3f}\"\n",
    "            \n",
    "            plt.title(title, fontsize=10, color=color, fontweight='bold')\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Afficher les statistiques\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    avg_confidence = np.mean(confidence_scores)\n",
    "    \n",
    "    print(f\"\\n📊 Statistiques sur ce batch:\")\n",
    "    print(f\"   🎯 Précision: {correct_predictions}/{total_predictions} ({accuracy*100:.1f}%)\")\n",
    "    print(f\"   📈 Confiance moyenne: {avg_confidence:.3f} ({avg_confidence*100:.1f}%)\")\n",
    "    print(f\"   🔍 Confiance min/max: {min(confidence_scores):.3f} / {max(confidence_scores):.3f}\")\n",
    "    \n",
    "    return correct_predictions, total_predictions, confidence_scores\n",
    "\n",
    "print(\"🔍 Prédictions sur le dataset de validation:\")\n",
    "correct, total, confidences = predict_and_show(ds_val_processed, model)\n",
    "\n",
    "print(\"\\n💡 Comment interpréter ces résultats ?\")\n",
    "print(\"   ✅ Prédictions correctes en VERT\")\n",
    "print(\"   ❌ Prédictions incorrectes en ROUGE\")\n",
    "print(\"   📊 La confiance indique la certitude du modèle (0-1)\")\n",
    "print(\"   🎯 Une confiance > 0.8 indique une prédiction très fiable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📊 Matrice de Confusion\n",
    "\n",
    "La matrice de confusion nous montre en détail quelles classes sont confondues par le modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "def create_confusion_matrix(dataset, model):\n",
    "    \"\"\"\n",
    "    Crée et affiche la matrice de confusion\n",
    "    \"\"\"\n",
    "    print(\"📊 Création de la matrice de confusion...\")\n",
    "    \n",
    "    # Collecter toutes les prédictions et vraies étiquettes\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "    \n",
    "    for images, labels in dataset:\n",
    "        # Prédictions du modèle\n",
    "        predictions = model.predict(images, verbose=0)\n",
    "        pred_labels = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        # Stocker les résultats\n",
    "        all_predictions.extend(pred_labels)\n",
    "        all_true_labels.extend(labels.numpy())\n",
    "    \n",
    "    # Créer la matrice de confusion\n",
    "    cm = confusion_matrix(all_true_labels, all_predictions)\n",
    "    \n",
    "    # Visualisation\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Nombre de prédictions'})\n",
    "    \n",
    "    plt.title('📊 Matrice de Confusion - Classification de Fleurs', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Classes Prédites', fontsize=12)\n",
    "    plt.ylabel('Classes Réelles', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyse de la matrice\n",
    "    print(\"\\n🔍 Analyse de la matrice de confusion:\")\n",
    "    \n",
    "    # Précision par classe\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        # Vrais positifs (diagonal)\n",
    "        tp = cm[i, i]\n",
    "        # Tous les exemples de cette classe\n",
    "        total_class = np.sum(cm[i, :])\n",
    "        # Précision pour cette classe\n",
    "        class_accuracy = tp / total_class if total_class > 0 else 0\n",
    "        \n",
    "        print(f\"   🌺 {class_name}: {tp}/{total_class} ({class_accuracy*100:.1f}%)\")\n",
    "    \n",
    "    # Identifier les confusions les plus fréquentes\n",
    "    print(\"\\n⚠️ Confusions les plus fréquentes:\")\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            if i != j and cm[i, j] > 0:\n",
    "                confusion_rate = cm[i, j] / np.sum(cm[i, :]) * 100\n",
    "                if confusion_rate > 10:  # Seulement les confusions > 10%\n",
    "                    print(f\"   🔄 {class_names[i]} → {class_names[j]}: {cm[i, j]} cas ({confusion_rate:.1f}%)\")\n",
    "    \n",
    "    # Rapport de classification détaillé\n",
    "    print(\"\\n📋 Rapport de classification détaillé:\")\n",
    "    report = classification_report(all_true_labels, all_predictions, \n",
    "                                 target_names=class_names, digits=4)\n",
    "    print(report)\n",
    "    \n",
    "    return cm, all_true_labels, all_predictions\n",
    "\n",
    "# Créer la matrice de confusion\n",
    "conf_matrix, true_labels, pred_labels = create_confusion_matrix(ds_val_processed, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Analyse des Erreurs\n",
    "\n",
    "Regardons en détail les cas où le modèle se trompe pour comprendre ses limites :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_errors(dataset, model, max_errors=6):\n",
    "    \"\"\"\n",
    "    Analyse et affiche les erreurs de classification\n",
    "    \"\"\"\n",
    "    print(\"🔍 Analyse des erreurs de classification...\")\n",
    "    \n",
    "    errors_found = []\n",
    "    \n",
    "    # Chercher des erreurs dans le dataset\n",
    "    for images, labels in dataset:\n",
    "        if len(errors_found) >= max_errors:\n",
    "            break\n",
    "            \n",
    "        predictions = model.predict(images, verbose=0)\n",
    "        pred_labels = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            if len(errors_found) >= max_errors:\n",
    "                break\n",
    "                \n",
    "            if pred_labels[i] != labels[i]:\n",
    "                errors_found.append({\n",
    "                    'image': images[i],\n",
    "                    'true_label': labels[i].numpy(),\n",
    "                    'pred_label': pred_labels[i],\n",
    "                    'confidence': predictions[i][pred_labels[i]],\n",
    "                    'true_confidence': predictions[i][labels[i]],\n",
    "                    'all_probs': predictions[i]\n",
    "                })\n",
    "    \n",
    "    if not errors_found:\n",
    "        print(\"🎉 Aucune erreur trouvée dans ce batch ! Modèle parfait sur ces exemples.\")\n",
    "        return\n",
    "    \n",
    "    # Affichage des erreurs\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle(\"❌ Analyse des Erreurs de Classification\", fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for idx, error in enumerate(errors_found[:6]):\n",
    "        row = idx // 3\n",
    "        col = idx % 3\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        # Afficher l'image\n",
    "        image = (error['image'].numpy() + 1) / 2  # Dénormaliser\n",
    "        ax.imshow(image)\n",
    "        \n",
    "        # Informations sur l'erreur\n",
    "        true_name = class_names[error['true_label']]\n",
    "        pred_name = class_names[error['pred_label']]\n",
    "        \n",
    "        title = f\"❌ Erreur #{idx+1}\\n\"\n",
    "        title += f\"✅ Vrai: {true_name} ({error['true_confidence']:.3f})\\n\"\n",
    "        title += f\"🎯 Prédit: {pred_name} ({error['confidence']:.3f})\"\n",
    "        \n",
    "        ax.set_title(title, fontsize=10, color='red', fontweight='bold')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Cacher les sous-graphiques vides\n",
    "    for idx in range(len(errors_found), 6):\n",
    "        row = idx // 3\n",
    "        col = idx % 3\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyse statistique des erreurs\n",
    "    print(f\"\\n📊 Analyse de {len(errors_found)} erreurs:\")\n",
    "    \n",
    "    # Confiance moyenne des erreurs\n",
    "    avg_error_confidence = np.mean([e['confidence'] for e in errors_found])\n",
    "    avg_true_confidence = np.mean([e['true_confidence'] for e in errors_found])\n",
    "    \n",
    "    print(f\"   📈 Confiance moyenne des prédictions erronées: {avg_error_confidence:.3f}\")\n",
    "    print(f\"   📉 Confiance moyenne des vraies classes: {avg_true_confidence:.3f}\")\n",
    "    print(f\"   📊 Différence de confiance: {avg_error_confidence - avg_true_confidence:.3f}\")\n",
    "    \n",
    "    # Types d'erreurs\n",
    "    error_types = {}\n",
    "    for error in errors_found:\n",
    "        true_class = class_names[error['true_label']]\n",
    "        pred_class = class_names[error['pred_label']]\n",
    "        error_type = f\"{true_class} → {pred_class}\"\n",
    "        error_types[error_type] = error_types.get(error_type, 0) + 1\n",
    "    \n",
    "    print(\"\\n🔄 Types d'erreurs les plus fréquents:\")\n",
    "    for error_type, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"   • {error_type}: {count} cas\")\n",
    "    \n",
    "    return errors_found\n",
    "\n",
    "# Analyser les erreurs\n",
    "errors = analyze_errors(ds_val_processed, model)\n",
    "\n",
    "print(\"\\n💡 Conseils pour améliorer le modèle:\")\n",
    "print(\"   🔍 Examinez les erreurs pour identifier les patterns\")\n",
    "print(\"   📊 Les classes souvent confondues nécessitent plus de données\")\n",
    "print(\"   🎲 L'augmentation de données peut aider pour les cas difficiles\")\n",
    "print(\"   🧠 Un modèle plus complexe peut distinguer les cas subtils\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎓 Conseils et Bonnes Pratiques\n",
    "\n",
    "### 📚 Ce que Nous Avons Appris\n",
    "\n",
    "À travers ce projet, nous avons exploré :\n",
    "\n",
    "✅ **Transfer Learning** : Utilisation d'un modèle pré-entraîné\n",
    "\n",
    "✅ **Fine-Tuning** : Ajustement fin en deux phases\n",
    "\n",
    "✅ **Data Augmentation** : Enrichissement artificiel des données\n",
    "\n",
    "✅ **Évaluation** : Mesure des performances et analyse des erreurs\n",
    "\n",
    "✅ **Visualisation** : Compréhension des résultats par les graphiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🚀 Conseils pour Améliorer Vos Modèles\n",
    "\n",
    "#### 1. 🎯 Choix du Modèle Pré-entraîné\n",
    "\n",
    "**Pour applications mobiles :**\n",
    "- MobileNet, MobileNetV2, MobileNetV3\n",
    "- EfficientNet (bon compromis taille/performance)\n",
    "\n",
    "**Pour performances maximales :**\n",
    "- ResNet50, ResNet101\n",
    "- EfficientNet-B4, B5, B7\n",
    "- Vision Transformers (ViT)\n",
    "\n",
    "**Pour données médicales :**\n",
    "- Modèles pré-entraînés sur ImageNet médical\n",
    "- Modèles spécialisés (RadImageNet, etc.)\n",
    "\n",
    "#### 2. 🎲 Stratégies d'Augmentation de Données\n",
    "\n",
    "**Augmentations géométriques :**\n",
    "```python\n",
    "# Basiques\n",
    "layers.RandomFlip(\"horizontal_and_vertical\")\n",
    "layers.RandomRotation(0.3)\n",
    "layers.RandomZoom(0.2)\n",
    "layers.RandomTranslation(0.1, 0.1)\n",
    "\n",
    "# Avancées\n",
    "layers.RandomContrast(0.2)\n",
    "layers.RandomBrightness(0.2)\n",
    "```\n",
    "\n",
    "**Augmentations spécialisées :**\n",
    "- **Photos de nature** : Variations de luminosité, contraste\n",
    "- **Images médicales** : Attention aux rotations (peut changer le diagnostic)\n",
    "- **Texte/Documents** : Rotations légères, perspective\n",
    "\n",
    "#### 3. 🔧 Stratégies de Fine-Tuning\n",
    "\n",
    "**Dégel progressif :**\n",
    "```python\n",
    "# Phase 1: Tout gelé\n",
    "base_model.trainable = False\n",
    "\n",
    "# Phase 2: Dégeler les dernières couches\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Phase 3: Dégeler plus de couches si nécessaire\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "```\n",
    "\n",
    "**Learning rates adaptatifs :**\n",
    "```python\n",
    "# LR différents pour différentes parties\n",
    "optimizer = tf.keras.optimizers.Adam([\n",
    "    {'params': base_model.layers[-10:], 'lr': 1e-5},\n",
    "    {'params': new_layers, 'lr': 1e-4}\n",
    "])\n",
    "```\n",
    "\n",
    "#### 4. 📊 Régularisation Avancée\n",
    "\n",
    "**Dropout adaptatif :**\n",
    "```python\n",
    "# Plus de dropout pour les couches plus larges\n",
    "x = layers.Dropout(0.3)(x)  # Après GlobalAveragePooling\n",
    "x = layers.Dense(512)(x)\n",
    "x = layers.Dropout(0.5)(x)  # Avant la couche finale\n",
    "```\n",
    "\n",
    "**Weight decay :**\n",
    "```python\n",
    "# L2 regularization\n",
    "layers.Dense(num_classes, \n",
    "            kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "```\n",
    "\n",
    "#### 5. ⚡ Optimisation des Performances\n",
    "\n",
    "**Mixed Precision Training :**\n",
    "```python\n",
    "# Pour GPUs modernes\n",
    "policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "tf.keras.mixed_precision.set_global_policy(policy)\n",
    "```\n",
    "\n",
    "**Pipeline de données optimisé :**\n",
    "```python\n",
    "dataset = dataset.cache()  # Cache en mémoire\n",
    "dataset = dataset.shuffle(1000)\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚠️ Erreurs Courantes à Éviter\n",
    "\n",
    "#### 🚨 Erreurs de Données\n",
    "- **Data leakage** : Même image dans train et validation\n",
    "- **Déséquilibre des classes** : Pas assez d'exemples pour certaines classes\n",
    "- **Qualité des labels** : Erreurs d'étiquetage\n",
    "\n",
    "#### 🚨 Erreurs d'Entraînement\n",
    "- **Learning rate trop élevé** : Le modèle n'apprend pas\n",
    "- **Learning rate trop faible** : Entraînement trop lent\n",
    "- **Pas assez d'époques** : Sous-apprentissage\n",
    "- **Trop d'époques** : Surapprentissage\n",
    "\n",
    "#### 🚨 Erreurs d'Évaluation\n",
    "- **Évaluer sur le train** : Surestimation des performances\n",
    "- **Pas de test set** : Pas de mesure finale objective\n",
    "- **Optimiser sur la validation** : Biais de sélection\n",
    "\n",
    "### 🎯 Prochaines Étapes\n",
    "\n",
    "Pour aller plus loin :\n",
    "\n",
    "1. **🔬 Expérimentez** avec d'autres architectures\n",
    "2. **📊 Collectez plus de données** pour améliorer les performances\n",
    "3. **🎲 Testez différentes augmentations** spécifiques à votre domaine\n",
    "4. **⚡ Optimisez pour la production** (quantization, pruning)\n",
    "5. **🚀 Déployez votre modèle** (TensorFlow Serving, TensorFlow Lite)\n",
    "\n",
    "### 📚 Ressources Supplémentaires\n",
    "\n",
    "- **Documentation TensorFlow** : [tensorflow.org](https://tensorflow.org)\n",
    "- **Papers avec Code** : [paperswithcode.com](https://paperswithcode.com)\n",
    "- **TensorFlow Hub** : Modèles pré-entraînés\n",
    "- **Keras Applications** : Architectures populaires\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
