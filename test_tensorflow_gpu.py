#!/usr/bin/env python3
"""
Script de test TensorFlow GPU
============================

Ce script teste votre installation TensorFlow et vÃ©rifie le support GPU.
Utilisation: python test_tensorflow_gpu.py

Auteur: Mickael Faust
Date: Juin 2025
"""

import sys
import os
import time
import subprocess

def print_section(title):
    """Affiche une section avec formatage"""
    print("\n" + "="*50)
    print(f" {title}")
    print("="*50)

def run_command(cmd):
    """ExÃ©cute une commande systÃ¨me et retourne le rÃ©sultat"""
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        return result.stdout.strip(), result.returncode == 0
    except Exception as e:
        return str(e), False

def main():
    print("ðŸš€ Test d'installation TensorFlow GPU")
    print("Auteur: Guide d'installation TensorFlow GPU - Juin 2025")

    # ===== INFORMATIONS SYSTÃˆME =====
    print_section("INFORMATIONS SYSTÃˆME")
    print(f"Python version: {sys.version}")
    print(f"Plateforme: {sys.platform}")
    print(f"Architecture: {os.uname().machine if hasattr(os, 'uname') else 'N/A'}")

    # Test nvidia-smi
    nvidia_output, nvidia_success = run_command("nvidia-smi --query-gpu=name,driver_version,memory.total --format=csv,noheader,nounits")
    if nvidia_success:
        print(f"âœ… NVIDIA Driver dÃ©tectÃ©:")
        for line in nvidia_output.split('\n'):
            if line.strip():
                print(f"   {line.strip()}")
    else:
        print("âŒ nvidia-smi non disponible ou pas de GPU NVIDIA")

    # ===== TEST TENSORFLOW =====
    print_section("TEST TENSORFLOW")

    try:
        import tensorflow as tf
        print(f"âœ… TensorFlow version: {tf.__version__}")

        # Informations de build
        try:
            build_info = tf.sysconfig.get_build_info()
            print(f"   - CUDA version: {build_info.get('cuda_version', 'N/A')}")
            print(f"   - cuDNN version: {build_info.get('cudnn_version', 'N/A')}")
        except:
            print("   - Informations build non disponibles")

    except ImportError as e:
        print(f"âŒ Erreur import TensorFlow: {e}")
        print("   Solution: VÃ©rifiez votre installation et environnement virtuel")
        return False

    # ===== TEST GPU =====
    print_section("TEST DÃ‰TECTION GPU")

    # Lister les devices
    physical_devices = tf.config.list_physical_devices()
    print("Devices physiques disponibles:")
    for device in physical_devices:
        print(f"   - {device}")

    # Test spÃ©cifique GPU
    gpu_devices = tf.config.list_physical_devices('GPU')
    print(f"\nNombre de GPUs dÃ©tectÃ©s: {len(gpu_devices)}")

    if len(gpu_devices) == 0:
        print("âŒ Aucun GPU dÃ©tectÃ© par TensorFlow")
        print("   Solutions possibles:")
        print("   - VÃ©rifiez les drivers NVIDIA (nvidia-smi)")
        print("   - RÃ©installez tensorflow[and-cuda]")
        print("   - VÃ©rifiez CUDA_VISIBLE_DEVICES")
        return False

    # Informations dÃ©taillÃ©es sur les GPUs
    for i, gpu in enumerate(gpu_devices):
        print(f"\nâœ… GPU {i}: {gpu}")
        try:
            details = tf.config.experimental.get_device_details(gpu)
            for key, value in details.items():
                print(f"   - {key}: {value}")
        except:
            print("   - DÃ©tails non disponibles")

    # ===== TEST CONFIGURATION MÃ‰MOIRE =====
    print_section("TEST CONFIGURATION MÃ‰MOIRE GPU")

    try:
        # Configurer la croissance mÃ©moire
        for gpu in gpu_devices:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("âœ… Croissance mÃ©moire GPU activÃ©e")

        # Informations mÃ©moire
        if len(gpu_devices) > 0:
            try:
                memory_info = tf.config.experimental.get_memory_info('GPU:0')
                print(f"   - MÃ©moire utilisÃ©e: {memory_info['current'] / 1024**3:.2f} GB")
                print(f"   - MÃ©moire limite: {memory_info['peak'] / 1024**3:.2f} GB")
            except:
                print("   - Informations mÃ©moire non disponibles")

    except Exception as e:
        print(f"âš ï¸  Configuration mÃ©moire Ã©chouÃ©e: {e}")

    # ===== TEST PERFORMANCE =====
    print_section("TEST PERFORMANCE")

    print("Test de calcul matriciel...")

    # Test CPU
    with tf.device('/CPU:0'):
        start_time = time.time()
        a = tf.random.normal([1000, 1000])
        b = tf.random.normal([1000, 1000])
        c = tf.matmul(a, b)
        cpu_time = time.time() - start_time

    print(f"âœ… CPU: {cpu_time:.4f}s")

    # Test GPU si disponible
    if len(gpu_devices) > 0:
        try:
            with tf.device('/GPU:0'):
                start_time = time.time()
                a = tf.random.normal([1000, 1000])
                b = tf.random.normal([1000, 1000])
                c = tf.matmul(a, b)
                gpu_time = time.time() - start_time

            print(f"âœ… GPU: {gpu_time:.4f}s")

            if gpu_time < cpu_time:
                speedup = cpu_time / gpu_time
                print(f"ðŸš€ AccÃ©lÃ©ration GPU: {speedup:.2f}x")
            else:
                print("âš ï¸  GPU plus lent que CPU (normal pour petites matrices)")

        except Exception as e:
            print(f"âŒ Erreur calcul GPU: {e}")

    # ===== TEST ENTRAÃŽNEMENT =====
    print_section("TEST ENTRAÃŽNEMENT SIMPLE")

    try:
        print("CrÃ©ation d'un modÃ¨le test...")

        # DonnÃ©es factices
        x_train = tf.random.normal([1000, 32])
        y_train = tf.random.uniform([1000, 1], maxval=2, dtype=tf.int32)

        # ModÃ¨le simple
        model = tf.keras.Sequential([
            tf.keras.layers.Dense(64, activation='relu', input_shape=(32,)),
            tf.keras.layers.Dense(32, activation='relu'),
            tf.keras.layers.Dense(1, activation='sigmoid')
        ])

        model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy']
        )

        print("EntraÃ®nement (2 epochs)...")
        start_time = time.time()

        history = model.fit(
            x_train, y_train,
            epochs=2,
            batch_size=32,
            verbose=0
        )

        training_time = time.time() - start_time
        print(f"âœ… EntraÃ®nement terminÃ© en {training_time:.2f}s")
        print(f"   - Loss finale: {history.history['loss'][-1]:.4f}")
        print(f"   - Accuracy finale: {history.history['accuracy'][-1]:.4f}")

    except Exception as e:
        print(f"âŒ Erreur entraÃ®nement: {e}")

    # ===== RÃ‰SUMÃ‰ FINAL =====
    print_section("RÃ‰SUMÃ‰ FINAL")

    if len(gpu_devices) > 0:
        print("ðŸŽ‰ SUCCÃˆS! TensorFlow GPU est correctement configurÃ©")
        print(f"   - {len(gpu_devices)} GPU(s) disponible(s)")
        print("   - Calculs GPU fonctionnels")
        print("   - EntraÃ®nement possible")

        # Recommandations pour optimiser
        print("\nðŸ“‹ Recommandations d'optimisation:")
        print("   - Utilisez des batch sizes plus importantes")
        print("   - Configurez la croissance mÃ©moire GPU")
        print("   - Utilisez mixed precision pour plus de performance")
        print("   - Exemple: model.compile(optimizer='adam', loss='mse', jit_compile=True)")

    else:
        print("âš ï¸  Configuration CPU uniquement")
        print("   - TensorFlow fonctionne mais sans accÃ©lÃ©ration GPU")
        print("   - Consultez le guide de dÃ©pannage")

    print("\nðŸ”— Ressources utiles:")
    print("   - Guide TensorFlow GPU: https://www.tensorflow.org/guide/gpu")
    print("   - CompatibilitÃ© CUDA: https://www.tensorflow.org/install/source#gpu")
    print("   - Forum TensorFlow: https://www.tensorflow.org/community")

    return len(gpu_devices) > 0

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
